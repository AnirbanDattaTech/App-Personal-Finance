# Project Status & Next Steps Summary (2025-04-24)

## I. Current Development Status

*   **Goal:** Phase 2 - Autonomous Multi-Agent Data Science Assistant.
*   **Current Stage:** Completed initial **single-agent prototype** implementation.
*   **Functionality:**
    *   A LangGraph agent (using Google Gemini `gemini-1.5-flash-latest`) handles simple natural language queries about financial expenses.
    *   The agent performs: Query Classification -> SQL Generation -> SQL Execution -> Basic Chart Generation -> Text Response Generation.
    *   A LangServe/FastAPI backend (`assistant/finance-assistant/app/server.py`) exposes this agent via an API endpoint (`/assistant/invoke`).
    *   A Streamlit frontend tab (`streamlit/tabs/assistant.py`) provides a chat interface.
    *   Streamlit UI successfully interacts with the backend API.
    *   UI displays chat history, the agent's final text response, a Plotly chart (if generated by the agent), and the raw SQL results (within an expander).
    *   Agent responses correctly use "INR" as the currency symbol.
*   **Technical Stack:** LangGraph, LangServe, FastAPI, Streamlit, Google Gemini, SQLAlchemy, Plotly, Pandas.
*   **Known Issues:**
    *   The `langgraph dev` command fails with a `TypeError: 'async for' requires an object with __aiter__ method...`.
    *   **Workaround:** Running the backend API directly using `uvicorn app.server:app --reload` works correctly and is the current method for development.
*   **Git Status:**
    *   The working single-agent prototype code has been committed and pushed to the `main` branch.
    *   A new branch `feature/agentic-ai` has been created from `main` and pushed to remote. Development will continue on this branch.

## II. Relevant File Structure & Logic

*   **Root Directory:** `app-personal-finance/`
*   **Configuration & Data:**
    *   `.env`: Contains `GOOGLE_API_KEY`.
    *   `data/expenses.db`: SQLite database with expense data.
    *   `metadata/expenses_metadata_detailed.yaml`: Detailed schema description used for SQL generation prompt.
*   **Backend Agent (LangGraph):** `assistant/finance-assistant/`
    *   `src/agent/graph.py`:
        *   Defines the `StateGraph` workflow.
        *   Contains node functions: `classify_query_node`, `generate_sql_node`, `execute_sql_node`, `generate_chart_node`, `generate_response_node`.
        *   Implements `should_continue` edge logic based on classification/errors.
        *   Initializes Gemini LLM and SQLAlchemy engine.
        *   Loads `SCHEMA_METADATA` from the YAML file.
        *   Compiles the workflow into the `graph` runnable.
    *   `src/agent/state.py`:
        *   Defines `AgentState` (TypedDict).
        *   Key fields: `original_query`, `classification`, `sql_query`, `sql_results_list` (List[Dict] - Changed from DataFrame for serialization), `sql_results_str`, `chart_json`, `final_response`, `error`.
    *   `app/server.py`:
        *   Sets up FastAPI application.
        *   Uses LangServe `add_routes` to expose the compiled `graph` at `/assistant`.
        *   Defines Pydantic models (`AssistantInput`, `AssistantOutput`) for API request/response validation and structure.
*   **Frontend UI (Streamlit):** `streamlit/`
    *   `main.py`: Main Streamlit app entry point, handles sidebar navigation, calls tab rendering functions.
    *   `tabs/assistant.py`:
        *   Renders the "Assistant" tab UI.
        *   Manages chat history in `st.session_state.messages`.
        *   Displays chat messages using `st.chat_message`.
        *   Handles user input via `st.chat_input`.
        *   Includes `call_assistant_api` function to send POST requests (using `requests`) to the LangServe backend (`http://localhost:8000/assistant/invoke`).
        *   Parses the API response (`output` key).
        *   Displays `final_response` (text).
        *   Uses `plotly.io.from_json` and `st.plotly_chart` to render `chart_json` (if present).
        *   Displays `sql_results_str` in an `st.expander`.

## III. Current Logic Flow (Single Agent - `graph.py`)

1.  **Input:** User query comes into `AgentState.original_query` via API.
2.  **Node `classify_query`:** Uses LLM to classify query into 'simple', 'advanced', or 'irrelevant'. Updates `AgentState.classification`.
3.  **Edge `should_continue`:**
    *   If 'irrelevant' or any `error` is set -> Go to Node `generate_response`.
    *   If 'simple' or 'advanced' -> Go to Node `generate_sql`.
4.  **Node `generate_sql`:** Uses LLM, prompt with schema details (`SCHEMA_METADATA`), and user query to generate an SQL query. Updates `AgentState.sql_query`. Handles prompt formatting errors.
5.  **Node `execute_sql`:** Executes `sql_query` using SQLAlchemy. Converts results to `List[Dict]` and updates `AgentState.sql_results_list`. Also creates a string representation and updates `AgentState.sql_results_str`. Handles SQL execution errors.
6.  **Node `generate_chart`:** Converts `sql_results_list` back to Pandas DataFrame. Applies simple heuristics (checks shape, column types) to decide between Line Chart, Bar Chart, or skipping chart generation. If a chart is generated, updates `AgentState.chart_json` with Plotly JSON.
7.  **Node `generate_response`:** Uses LLM, prompt including user query, `sql_results_str`, chart availability status, and INR currency instruction. Generates the final text summary. Updates `AgentState.final_response`. Also formats responses for error states or 'irrelevant' classifications.
8.  **END:** Graph execution finishes. LangServe returns the final state fields specified in `AssistantOutput` (excluding `sql_results_list`).

## IV. Next Steps (on `feature/agentic-ai` branch)

1.  **Design Multi-Agent Architecture:** Plan the interaction flow between the required agents (Super Agent - SA, Data Analyst Agent - DAA, Data Visualization Agent - DVA, Data Scientist Agent - DSA) based on `requirement_v2_ds_assistant.txt`. Define responsibilities and communication protocols (likely modifying/extending `AgentState` or using separate states).
2.  **Implement Super Agent (SA):**
    *   Create a new LangGraph graph (or refactor the existing one) to act as the orchestrator.
    *   Refine the initial query classification step (Simple, Advanced, Irrelevant).
    *   Implement routing logic using conditional edges to invoke the appropriate sub-agent (DAA or DSA) based on classification.
    *   Manage the overall conversation flow and state aggregation.
3.  **Implement Data Analyst Agent (DAA):**
    *   Create a dedicated LangGraph (or Runnable sequence) for DAA tasks.
    *   Migrate/adapt the current `generate_sql_node` and `execute_sql_node` logic.
    *   **Enhance DAA:** Implement Entity Extraction (e.g., using LLM function calling or specific libraries) and Metadata Similarity Search (potentially using RAG with embeddings on `expenses_metadata_detailed.yaml` content) to improve SQL generation robustness, as required.
4.  **Implement Data Visualization Agent (DVA):**
    *   Create a dedicated LangGraph/Runnable for DVA tasks.
    *   Migrate/adapt the current `generate_chart_node`.
    *   **Enhance DVA:** Explore using an LLM call within the DVA to *select* the best chart type based on the user query and the data structure (from DAA), rather than relying solely on heuristics. Define the 7 allowed chart types clearly in the prompt.
5.  **Plan Data Scientist Agent (DSA):**
    *   Outline the structure for the DSA. This will involve:
        *   Classifying the 'advanced' query into one of the 5 ML types (Regression, Forecasting, Classification, Segmentation, Clustering).
        *   Defining the interaction with DAA to fetch necessary data.
        *   Implementing pre-defined ML workflows (likely using libraries like Scikit-learn, Statsmodels, etc.) triggered by the classification.
        *   Formatting ML model outputs and summaries.
        *(This is a larger task and can be broken down further)*.
6.  **Implement Conversation History:**
    *   Modify `streamlit/tabs/assistant.py` to store more than just the last message pair in `st.session_state.messages`.
    *   Update `call_assistant_api` to potentially include relevant parts of the conversation history in the payload sent to the backend Super Agent.
    *   Update the Super Agent's initial prompt/logic to incorporate conversation history for context awareness.
7.  **Refine LangSmith Tracing:** Actively use LangSmith to monitor the more complex traces that will arise from the multi-agent interactions, debugging state flow and agent handoffs.