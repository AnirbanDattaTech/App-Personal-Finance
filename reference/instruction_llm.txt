Uploading the necessary files and reference links for context, read and understand:

INSTRUCTION_LLM: Specific instructions for you to follow: instruction_llm.txt, *THIS FILE*
INITIAL_REQUIREMENT (PHASE 1: DONE): requirement_v1_streamlit_app.txt - PHASE 1: This is the INITIAL REQUIREMENT. FOR UNDERSTANDING INITIAL SCOPE ONLY. CURRENT IMPLEMENTATION HAS CHANGED. REFER TO CODEBASE FOR CURRENT STATE.
CURRENT_REQUIREMENT (PHASE 2: ONGOING): reference/requirement_v2_ds_assistant.txt - PHASE 2: This is the CURRENT REQUIREMENT.
PROJECT_STRUCTURE: reference/instruction_file_tree.txt
PROJECT_CODE_FILE_CONTENT: reference/instruction_code_details_compressed.txt
SAMPLE_DATA: expenses_sample.csv
SAMPLE_METADATA: expense_metadata.json

REQUIREMENT: Help me build an autonomous, multi agent data science assistant for my personal finances app (Refer: CURRENT_REQUIREMENT) through code generation and brainstorming.

PUBLIC GIT REPO FOR PROJECT: https://github.com/AnirbanDattaTech/App-Personal-Finance.git

Ensure, for all future project steps, code generation and brainstorming:
✅ Code generation - ALWAYS first start with a detailed understanding of the current implemented code (PROJECT_CODE_FILE_CONTENT). Understanding the current implementation and ensuring the generated code is compatible with the current codebase is *CRITICAL*.
✅ Code generation - ALWAYS write code compatible with openai >1.0.0 ENSURE openai current version.
✅ Code generation - Always recommend whether using base python scripts/ml (sklearn etc)/dl (torch etc)/ gen ai (llms) / agentic ai (llm + langgraph etc) will be most efficient for a certain request. Don't automatically follow suggestions. Recommend alternate, more efficient and better options first.
✅ Code generation - Always generate full code block for the .py files
✅ Code generation - Always include detailed explanation of code with remarks / comments in the code file
✅ Code generation - Always include proper python structure and type hints
✅ Code generation - All libraries are installed, imports are correct, versions are latest and no  version conflicts.
✅ Code generation - Ensure all python generated images have proper chart titles, x and y axis names, graphs and charts
✅ Paths-	Always use relative paths correctly (Path(__file__).parent / "...")
✅ Variables-	No undefined variables or misused constants
✅ Imports-	Fully compatible with current langchain, langgraph, langgraph-cli, openai, pydantic versions 
✅ Data Validation-	use Pydantic whereever applicable
✅ Output-	Files are correctly created with headers, even if fallback is needed
✅ File paths-	All file paths and relative paths are correct based on project dir (PROJECT_STRUCTURE)
✅ Prompt files-	all prompt files are referrenced correctly in code
✅ Output dirs-	all dirs (inputs and outputs) are validated
✅ Model- gpt-4o or fallback gpt-3.5-turbo
✅ detailed step by step instructions (dsbsi from now).

FOR ME ----
I will use #context snapshot command in gpt plus to create a snapshot.
I can also do:
	#context snapshot assistant → only assistant design summary
	#context snapshot codebase → current code files in use
	#context snapshot ml → ML modeling or DSA-related setup
	#context snapshot todo → list of pending next steps